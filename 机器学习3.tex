\documentclass{article}
\usepackage{graphicx}
\usepackage{CJKutf8}
\usepackage{amsmath}
\usepackage{minted}
\usepackage[boxed]{algorithm2e}
\begin{document}
\begin{CJK}{UTF8}{gbsn}
\title{机器学习3}
\date{}
\maketitle
\section{Gradient Descent For Multiple Variables}
\paragraph{}
The gradient descent equation itself is generally the same form; we just have to repeat it for our 'n' features:
\begin{algorithm} 
\paragraph{}
repeat until convergence:$\lbrace$
\paragraph{}
$\theta_{0}:=\theta_{0}-\alpha\frac{1}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})\cdot$ $x^{(i)}_{0}$
\paragraph{}
$\theta_{1}:=\theta_{1}-\alpha\frac{1}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})\cdot$ $x^{(i)}_{1}$
\paragraph{}
$\theta_{2}:=\theta_{2}-\alpha\frac{1}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})\cdot$ $x^{(i)}_{2}$
\paragraph{}
$\cdots$
\paragraph{}
$\rbrace$
\end{algorithm}
\paragraph{}
In other words:
\begin{algorithm}
\paragraph{}
repeat until convergence:$\lbrace$
\paragraph{}
$\theta_{j}:=\theta_{j}-\alpha\frac{1}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})\cdot x^{(i)}_{j}$            \qquad $for j:=0...n$
\paragraph{}
$\rbrace$
\end{algorithm}
\paragraph{}
The following image compares gradient descent with one variable to gradient descent with multiple variables:
\paragraph{}
\includegraphics[width = .9\textwidth]{a.png}
\section{Gradient Descent in Practice I - Feature Scaling
}
\paragraph{}
Note: [6:20 - The average size of a house is 1000 but 100 is accidentally written instead]
\paragraph{}
We can speed up gradient descent by having each of our input values in roughly the same range. This is because θ will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.
\paragraph{}
The way to prevent this is to modify the ranges of our input variables so that they are all roughly the same. Ideally:
\paragraph{}
$-1\leq x_{(i)}\leq1$
\paragraph{}
or
\paragraph{}
$-0.5\leq x_{(i)}\leq0.5$
\paragraph{}
These aren't exact requirements; we are only trying to speed things up. The goal is to get all input variables into roughly one of these ranges, give or take a few.
\paragraph{}
Two techniques to help with this are \textbf{feature scaling} and \textbf{mean normalization}. Feature scaling involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1. Mean normalization involves subtracting the average value for an input variable from the values for that input variable resulting in a new average value for the input variable of just zero. To implement both of these techniques, adjust your input values as shown in this formula:
\paragraph{}
$x_{i}:=\dfrac{x_{i}-\mu_{i}}{s_{i}}$
\paragraph{}
Where $\mu_{i}$ is the \textbf{average} of all the values for feature (i) and $s_{i}$ is the range of values (max - min), or $s_{i}$ is the standard deviation.
\paragraph{}
Note that dividing by the range, or dividing by the standard deviation, give different results. The quizzes in this course use range - the programming exercises use standard deviation.
\paragraph{}
For example, if xi represents housing prices with a range of 100 to 2000 and a mean value of 1000, then, xi:=$\dfrac{price-1000}{1900}$.
\section{Gradient Descent in Practice II - Learning Rate}
\paragraph{}
\textbf{Note:} [5:20 - the x -axis label in the right graph should be θ rather than No. of iterations ]
\paragraph{}
\textbf{Debugging gradient descent.}Make a plot with number of iterations on the x-axis. Now plot the cost function, J(θ) over the number of iterations of gradient descent. If J(θ) ever increases, then you probably need to decrease α.
\paragraph{}
\textbf{Automatic convergence test.}Declare convergence if J(θ) decreases by less than E in one iteration, where E is some small value such as $10^{-3}$. However in practice it's difficult to choose this threshold value.
\paragraph{}
\includegraphics[width = .9\textwidth]{b.png}
\paragraph{}
\includegraphics[width = .9\textwidth]{c.png}
\paragraph{}
To summarize:
\paragraph{}
If α is too small: slow convergence.
\paragraph{}
If α is too large: ￼may not decrease on every iteration and thus may not converge. 
\section{Features and Polynomial Regression}
\paragraph{}
We can improve our features and the form of our hypothesis function in a couple different ways.
\paragraph{}
We can \textbf{combine} multiple features into one. For example, we can combine $x_{1}$ and $x_{2}$ into a new feature $x_{3}$ by taking $x_{1}⋅x_{2}$.
\paragraph{}
\textbf{Polynomial Regression}
\paragraph{}
Our hypothesis function need not be linear (a straight line) if that does not fit the data well.
\paragraph{}
We can \textbf{change the behavior or curve} of our hypothesis function by making it a quadratic, cubic or square root function (or any other form).
\paragraph{}
For example, if our hypothesis function is $h_{\theta}(x)=\theta_{0}+\theta_{1}x_{1}$ then we can create additional features based on $x_{1}$, to get the quadratic function $h_{\theta}(x)=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{1}^{2} $or the cubic function $h_{\theta}(x)=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{1}^{2}+\theta_{3}x_{1}^{3}$
\paragraph{}
In the cubic version, we have created new features $x_{2}$ and $x_{3}$ where $x_{2}=x_{1}^{2}$ and $x_{3}=x_{1}^{3}$.
\paragraph{}
To make it a square root function, we could do: $h_{\theta}(x)=\theta_{0}+\theta_{1}x_{1}+\theta_{2}\sqrt{x_{1}}$
\paragraph{}
One important thing to keep in mind is, if you choose your features this way then feature scaling becomes very important.
\paragraph{}
eg. if $x_{1}$ has range 1 - 1000 then range of $x_{1}^{2}$ becomes 1 - 1000000 and that of $x_{1}^{3}$ becomes 1 - 1000000000
\section{Normal Equation}
\paragraph{}
\textbf{Note:} [8:00 to 8:44 - The design matrix X (in the bottom right side of the slide) given in the example should have elements x with subscript 1 and superscripts varying from 1 to m because for all m training sets there are only 2 features $x_{0}$ and $x_{1}$. 12:56 - The X matrix is m by (n+1) and NOT n by n. ]
\paragraph{}
Gradient descent gives one way of minimizing J. Let’s discuss a second way of doing so, this time performing the minimization explicitly and without resorting to an iterative algorithm. In the "Normal Equation" method, we will minimize J by explicitly taking its derivatives with respect to the $\theta_{j}’s$, and setting them to zero. This allows us to find the optimum theta without iteration. The normal equation formula is given below:
\paragraph{}
$\theta=(X^{T}X)^{-1}X^{T}y$
\paragraph{}
\includegraphics[width = .9\textwidth]{d.png}
\paragraph{}
There is \textbf{no need} to do feature scaling with the normal equation.
\paragraph{}
The following is a comparison of gradient descent and the normal equation:
\begin{tabular}{|l|c|r|}
\hline
Gradient Descent&Normal Equation\\
\hline
Need to choose alpha&No need to choose alpha\\
\hline
O(k $n^{2}$)&O ($n^{3}$), need to calculate inverse of $X^{T}X$\\
\hline
Works well when n is large&Slow if n is very large\\
\hline
\end{tabular}
\paragraph{}
With the normal equation, computing the inversion has complexity $\Theta(n^{3})$. So if we have a very large number of features, the normal equation will be slow. In practice, when n exceeds 10,000 it might be a good time to go from a normal solution to an iterative process.
\end{CJK}
\end{document}